<h3>Face Recognition at a Distance</h3>
<p>Performing facial recognition at longer ranges presents many additional problems compared to user cooperative recognition at close range. The 4 main factors can be categorised as: technology, environment, user and user-system interaction. Together, these 4 factors affect the quality of the images that are captured, which presents a challenge for recognition systems having to deal with this reduced quality.</p>
<p>To create a robust facial recognition system that can work at mid to longer ranges, you need to overcome image quality issues caused by resolution, focus, interlace effects and motion blur. Low resolution is caused by the view of the camera being wide, and the proportion of the image that the face takes up being small. This causes the image of the face (once cropped from the rest of the image) to usually be very low resolution. While researchers are still a long way from developing reliable algorithms to deal with these low resolution images, the current solution to the problem is remarkably simple: just use a camera with a higher resolution sensor to capture the face images.</p>
<img class='text-image' src='public/img/low-res.jpg'/>
<div class='image-caption'>
  &lt;A simple example of how low resolution sensors can lead to image blur.&gt;
  <a>Source: Handbook for Remote Biometrics</a>
</div>
<p>It is very rare that the face will be perfectly in focus in a captured image. The lack of clear focus is often caused by defects in the imaging optics causing the image to become slightly blurred. The blurring effects of the defects tend to be enhanced as the aperture diameter of the lens increases, so a simple way to combat this is to use as small an aperture as possible. However, this causes other issues as using a small aperture reduces the amount of light entering the sensor so can lead to the appearance of poor illumination in the image. The other issue with using a small aperture is that this will require a slower shutter speed, which can cause increased motion blur. It is therefore difficult to balance the aperture and shutter speed to minimise both motion blur and blur caused by aberrations in the lens.</p>
<img class='text-image' src='public/img/motion-blur.jpg'/>
<div class='image-caption'>
  &lt;Image blur caused by fast motion during the image capture.&gt;
  <a>Source: Handbook for Remote Biometrics</a>
</div>
<p>Interlacing effects are caused by the way in which video is displayed on an electronic display. Video footage is interlaced when it is displayed on a screen. Every still image (also known as a field) of the video is interlaced with the next field when displayed on the screen, so that the content of one field is shown on all the odd-numbered lines on the screen and the content of the other field is used on the even lines. Because each frame of interlaced video is actually composed of 2 images captured a few moments apart, the frames displayed on screen can show motion artefacts if the faces move during between the 2 images being captured. A solution to try and remove these motion artefacts is to apply de-interlacing procedures to the footage, although this usually results in a lower resolution image which itself causes more issues as we previously discusssed. The ultimate solution to the interlaced video problem is to use progressive scan video systems. </p>
<img class='text-image' src='public/img/interlacing.jpg'/>
<div class='image-caption'>
  &lt;An example of interlacing effects leading to poor image quality of an image captured by a CCTV camera.&gt;
  <a>Source: Handbook for Remote Biometrics</a>
</div>
<h4>Dealing with Different Users</h4>
<p>One of the biggest issues that a user cooperative system faces is covering the full range of users heights. There are 2 main options: either use a single camera with a wide field of view, or use multiple cameras. Most camera sensors have an aspect ration of 4:3 or 16:9 so rotating the sensor by 90 degrees provides a taller field of view for covering different user heights. The disadvantage of this is that it reduces the proportion of an image that a face will take up. For this reason, using a wide field of view camera always requires the use of a high resolution sensor to maintain sufficient quality. The other option involves using multiple cameras to cover different heights. Now you have multiple images of the user from different heights, which you can either merge to form a single image, or use the images independently. Taking either approach presents problems, as merging the images requires extra effort during pre-processing, and using the images individually requires ensuring that the images overlap slightly so that the face is not cut in two.</p>
<p>Another problem facial recognition systems need to deal with is that of user attention. Most algorithms currently in use require a frontal face image to ensure a high level of accuracy and speed. This yields the question: how can you make the user face the camera? Systems that can make use of user cooperation can solve this problem fairly easily, as you can simply place a screen or display below the camera showing a live feed from the camera, so that the user can position themselves in the optimal position. Other systems however, that cannot rely on user cooperation such as those used for watch-list surveillance do not have this luxury. It is very difficult to capture optimal images without the cooperation of the user, and this is why active research is still being carried out to try and develop new algorithms that work equally as well with less than ideal frontal face images. The current solution to this problem is to simply use multiple cameras covering different angles, in the hope that at least one will capture a sufficiently clear image.</p>
<p>In this scenario of face surveillance where the user is not cooperative, facial recognition systems need to also be able to follow the faces of individuals even when the individual is not facing the camera. Systems also need to be able to keep track of a certain individual in a crowded environment when other faces may obscure the target face. To achieve this, and mitigate the negative effects of motion blur the system should be able to both track and recognise an individuals face. This requires that a face tracking module works in conjunction with a recognition module, as shown in the diagram below. </p>
<img class='text-image' src='public/img/tracking-and-recognition.jpg'/>
<div class='image-caption'>
  &lt;A diagram showing how tracking and recognition technologies can be combined to form a facial recognition system capable of face surveillance such as for criminal watchlists.&gt;
  <a href='http://www.face-rec.org/algorithms/comparisons/delac_03.pdf'>Source: Independent Comparative Study of PCA, ICA, and LDA on the FERET Data Set</a>
</div>

