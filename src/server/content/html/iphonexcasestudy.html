<h4>Case Study: iPhone X Face ID</h4>
<img class='text-image' src='public/img/iphone-x-face-id.jpg'/>
<div class='image-caption'>
  &lt;The array of sensors that make up the external hardware required for the Face ID facial recognition system on the Apple iPhone X.&gt;
  <a href='http://www.idownloadblog.com/2017/10/12/himax-technologies-shipping-iphone-x-face-id-chips/'>Source: idownloadblog.com</a>
</div>
<p>In September 2017, Apple launched the iPhone X with its first generation Face ID biometric security system, designed to replace the Touch ID fingerprint sensor that had been present in iPhone’s previously.</p>
<p>The Face ID system works in a verification setting, as the system is designed to only have one authorised user: the owner of the phone. Therefore, after a user has enrolled their face, the template is stored on chip and this is the only template that can successfully unlock the phone, so any face that is scanned when trying to unlock the phone only has to be compared to the single user template stored on chip that corresponds to the owner of the phone.</p>
<p>The TrueDepth camera (Apple’s branding for the array of sensors and cameras on the front of the phone that make up the required hardware for the Face ID system) uses the proximity sensor to actively look for a user’s face once the phone has been interacted with (e.g. picked up, screen turned on etc.). Once a face has been detected, Face ID looks for user attention and intent before attempting to unlock the phone: it does this by looking for the user’s eyes to be open and focusing on the device.</p>
<p>Once the system has confirmed that the user is awake and has intent to unlock the phone, the dot projector projects 30,000 infrared dots onto the user’s face, and the infrared camera takes an infrared image of the face with the dot map projected on it. This is used to form a <a href="/2Dvs3D">3D depth map</a> of the face by analysing the displacement of the dots. Standard 2D images of the face are also captured (if the setting is dark, the flood illuminator projects IR light so the cameras can operate effectively). The depth maps and 2D infrared images are then combined and transformed into a mathematical representation that is stored in the ‘Secure Enclave’: this is a coprocessor inside the CPU that uses encrypted memory to store biometric data.</p>
<p>The matching of a user’s face to the enrolled template takes place inside the Secure Enclave, using specially trained <a href="/CNNs">neural networks</a>. Apple says that these neural networks were trained using over a billion images, including infrared and depth images collected from users of all genders, ages and ethnicities. Apple claims that the probability that a random person in the population could unlock your phone using Face ID is 1 in 1,000,000, but admits that the probability of a false match is different for family members: in particular for twins, siblings and children under the age of 13.</p>
