<h4>Illumination in facial recognition</h4>
<p>
  Another problem that facial recognition must deal with is illumination. Most current facial recognition technologies focus upon the analysis and classification of the photometric properties of an image. This means that a change in any photometric property are treated equivalently, and the changes from illumination is treated the same as changes due to shape deformations. Several techniques have been introduced to help counteract this problem, and these techniques can be classified into three general categories.
</p>
<p>
  Histogram Based Adaptive Techniques attempt to normalize the light intensity throughout the face using histogram techniques. In general, techniques in this category will divide an input face image into sub-regions, and calculate a histogram chart of the light intensity of all the sub-regions. After that, it adjusts the input light intensity through filtering until a normalized histogram light intensity chart is produced.
</p>
<p>
  Illumination-invariant Representation Analysis attempts to use illumination invariant features to aid in the identification process. An input image has several illumination-invariant features that can be exploited to help with the analysis process, such as the hue of the input image (not affected by actual light levels), and face space manifolds. These invariant features alone are usually not accurate enough to identify a face alone, but provides a useful addition to the analysis process.
</p>
<p>
  Relighting techniques attempts to calculate the skin reflectance off the face, which is an illumination-invariant value, and use it to digitally relight the face. This technique is seen to be complex and merely an estimation, due to the physics of skin tissues (the skin absorbs a portion of light, different thicknesses of skin layers determine the different amounts of skin reflectance etc.) making it hard for modern systems to determine and predict light behaviour on the skin. This technique takes each pixel-by-pixel and attempts to individually build up an idea of the level of skin reflectance the input image has, and then relights it based on that value.
</p>
<p>
  There have been several improvements made to each individual category in recent studies. These reflect the active interest in illumination related problems in facial recognition, which remains far from solved. For example, a paper released on relighting techniques initially builds a canonical image of the face through the estimation of 9 low-light components of the image.
</p>
<p>
  After that, new input images can be reduced into its normalised forms using simple light reduction from the nine components [Fig 1], and be compared to the canonical form of the original image. This technique records an 5-70% improvement on categorising images with poor illumination conditions, at the costs of higher processing time, as well as being limited to images with not too extreme illumination conditions.
</p>
<img class='text-image' src='public/img/light-faces.jpg'/>
<div class='image-caption'>
  &lt;Fig.1 Relighting results, the images in the first row are the original input face images, the images in the second and third row are the results of normalising the facial features&gt;
<a href='http://ieeexplore.ieee.org/document/1327215/?reload=true'>Source: Face relighting for face recognition under generic illumination</a>
</div>
<p>
  Although there has not been a consensus solution to the problem of illumination, the three aforementioned categories are each making a stride towards either sidestepping or dealing with illumination directly.
</p>
